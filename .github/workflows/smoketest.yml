name: Build MPAS-A Inside NCAR HPC Development Containers

# This workflow is used to build and run MPAS-A inside NCAR HPC development containers.
# It's adapted from Ben Kirk's workflows building & testing dev containers with github actions
# NCAR/CISL Docker Hub: https://hub.docker.com/u/ncarcisl
# Ben Kirk's workflows: https://github.com/benkirk/demo_github_actions


on:
  workflow_dispatch:
    inputs:
        os:
          description: 'Base OS'
          type: choice
          required: true
          default: almalinux9
          options:
            - almalinux8
            - almalinux9
            - almalinux10
            - leap
            - tumbleweed
            - noble

jobs:

  build-mpas:
    strategy:
      fail-fast: false
      matrix:
        #compiler: [ nvhpc, oneapi, aocc, gcc, gcc12, gcc13, gcc14, clang ]
        compiler: [ nvhpc, gcc ]
        mpi:      [ mpich, mpich3 ]
        #gpu:      [ nogpu, cuda ]
        gpu:      [ nogpu ]
        io:       [ smiol ]
        arch:     [ x86_64 ]

        include:
          #- mpi: openmpi
          #  extra_mpi_args: 'export MPI_FLAGS="--allow-run-as-root --oversubscribe"'
          - mpi: mpich3
            extra_mpi_args: 'export MPI_FLAGS=""'
          - mpi: mpich
            extra_mpi_args: 'export MPI_FLAGS=""'
          - io: smiol
            extra_io_args: 'unset PIO'
          #- io: pio
          #  extra_io_args: 'export PIO_ROOT=${PIO_ROOT:-/container/pio}; export USE_PIO2=true'
          #- compiler: nvhpc
          #  gpu: cuda
          #  extra_accel_args: 'export OPENACC=true'


    name: Build MPAS-A
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -elo pipefail {0}

    container:
      image: ncarcisl/cisldev-${{ matrix.arch }}-${{ inputs.os }}-${{ matrix.compiler }}-${{ matrix.mpi }}${{ matrix.gpu == 'cuda' && '-cuda' || '' }}:devel
    
    steps:
      - uses: actions/checkout@v4

      - name: Interrogate Runtime Environment
        run: |
          echo "=== Container Environment ==="
          cat /container/config_env.sh
          echo
          echo "=== System Information ==="
          pwd
          echo "Container OS:"
          cat /etc/os-release 2>/dev/null || echo "OS info not available"
          uname -a
          echo
          echo "=== Hardware Information ==="
          lscpu | head -10
          nvidia-smi 2>/dev/null || echo "No NVIDIA GPU detected"
          df -h | head -5
          echo
          echo "=== Compiler Information ==="
          echo "CC=${CC}"
          echo "CXX=${CXX}"
          echo "FC=${FC}"
          echo "F77=${F77}"
          echo
          echo "CFLAGS=${CFLAGS}"
          echo "CPPFLAGS=${CPPFLAGS}"
          echo "CXXFLAGS=${CXXFLAGS}"
          echo "FCFLAGS=${FCFLAGS}"
          echo "F77FLAGS=${F77FLAGS}"
          export CC CXX FC F77 CFLAGS CXXFLAGS FCFLAGS F77FLAGS CPPFLAGS
          echo
          echo "=== Library Versions ==="
          which conda 2>/dev/null && conda --version || echo "conda: not available"
          which mpicc && mpicc --version 2>/dev/null || echo "mpicc: not available"
          which mpirun && mpirun --version 2>/dev/null || echo "mpirun: not available"
          which cmake && cmake --version 2>/dev/null || echo "cmake: not available"
          which make && make --version 2>/dev/null | head -1 || echo "make: not available"

      - name: Build MPAS-A
        continue-on-error: false
        run: |
          chmod +x .github/workflows/build_mpas.sh

          # Use extra_io_args to set whether to use PIO or SMIOL
          if [ -n "${{ matrix.extra_io_args }}" ]; then
            eval "${{ matrix.extra_io_args }}"
          fi

          # Use extra_accel_args to set whether to use OpenACC
          if [ -n "${{ matrix.extra_accel_args }}" ]; then
            eval "${{ matrix.extra_accel_args }}"
          fi
          timeout 25m .github/workflows/build_mpas.sh

      - name: Upload atmosphere_model executable
        uses: actions/upload-artifact@v4
        with:
          name: atmosphere_model-${{ matrix.compiler }}_${{ matrix.mpi }}_${{ matrix.gpu }}_${{ matrix.io }}
          path: atmosphere_model
  
  run-mpas-240km:

    # The run-mpas-240km matrix needs to be a subset of the build-mpas matrix
    # at this time

    
    strategy:
      fail-fast: false
      matrix:
        #compiler: [ nvhpc, oneapi, aocc, gcc, gcc12, gcc13, gcc14, clang ]
        compiler: [ nvhpc, gcc ]
        mpi:      [ mpich, mpich3 ]
        gpu:      [ nogpu ]
        io:       [ smiol ]
        arch:     [ x86_64 ]
        num_procs: [ 1, 4 ]

        include:
          #- mpi: openmpi
          #  extra_mpi_args: 'export MPI_FLAGS="--allow-run-as-root --oversubscribe"'
          - mpi: mpich3
            extra_mpi_args: 'export MPI_FLAGS=""'
          - mpi: mpich
            extra_mpi_args: 'export MPI_FLAGS=""'
          - io: smiol
            extra_io_args: 'unset PIO'
          #- io: pio
          #  extra_io_args: 'export PIO_ROOT=${PIO_ROOT:-/container/pio}; export USE_PIO2=true'

    needs: build-mpas
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -elo pipefail {0}

    container:
      image: ncarcisl/cisldev-${{ matrix.arch }}-${{ inputs.os }}-${{ matrix.compiler }}-${{ matrix.mpi }}${{ matrix.gpu == 'cuda' && '-cuda' || '' }}:devel
    
    steps:
      - uses: actions/checkout@v4

      - name: Interrogate Runtime Environment
        run: |
          echo "=== Container Environment ==="
          cat /container/config_env.sh
          echo
          echo "=== System Information ==="
          pwd
          echo "Container OS:"
          cat /etc/os-release 2>/dev/null || echo "OS info not available"
          uname -a
          echo
          echo "=== Hardware Information ==="
          lscpu | head -10
          nvidia-smi 2>/dev/null || echo "No NVIDIA GPU detected"
          df -h | head -5
          echo
          echo "=== Compiler Information ==="
          echo "CC=${CC}"
          echo "CXX=${CXX}"
          echo "FC=${FC}"
          echo "F77=${F77}"
          echo
          echo "CFLAGS=${CFLAGS}"
          echo "CPPFLAGS=${CPPFLAGS}"
          echo "CXXFLAGS=${CXXFLAGS}"
          echo "FCFLAGS=${FCFLAGS}"
          echo "F77FLAGS=${F77FLAGS}"
          export CC CXX FC F77 CFLAGS CXXFLAGS FCFLAGS F77FLAGS CPPFLAGS
          echo
          echo "=== Library Versions ==="
          which conda 2>/dev/null && conda --version || echo "conda: not available"
          which mpicc && mpicc --version 2>/dev/null || echo "mpicc: not available"
          which mpirun && mpirun --version 2>/dev/null || echo "mpirun: not available"
          which cmake && cmake --version 2>/dev/null || echo "cmake: not available"
          which make && make --version 2>/dev/null | head -1 || echo "make: not available"

      - name: Download atmosphere_model executable
        uses: actions/download-artifact@v4
        with:
          name: atmosphere_model-${{ matrix.compiler }}_${{ matrix.mpi }}_${{ matrix.gpu }}_${{ matrix.io }}
          path: 

      - name: Make atmosphere_model executable
        run: chmod +x atmosphere_model

      - name: Run MPAS-A 240km case with ${{ matrix.num_procs }} ranks
        run: |
          chmod +x .github/workflows/run_mpas_240km.sh

          # Use extra_mpi_args to set MPI implementation
          if [ -n "${{ matrix.extra_mpi_args }}" ]; then
            eval "${{ matrix.extra_mpi_args }}"
          fi
          .github/workflows/run_mpas_240km.sh ${{ matrix.num_procs }}

      - name: Print log.atmosphere.0000.out
        if: always()
        run: |
          cat 240km_${{ matrix.num_procs }}/log.atmosphere.0000.out

      - name: Print log.atmosphere.0000.err
        if: always()
        run: |
          # check if log.atmosphere.0000.err exists
          if [ -f 240km_${{ matrix.num_procs }}/log.atmosphere.0000.err ]; then
            cat 240km_${{ matrix.num_procs }}/log.atmosphere.0000.err
          else
            echo "log.atmosphere.0000.err not created"
          fi

      - name: Upload log and error files
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mpas_240km_${{ matrix.num_procs }}rank_error_${{ matrix.compiler }}_${{ matrix.mpi }}_${{ matrix.gpu }}_${{ matrix.io }}
          path: |
            240km_${{ matrix.num_procs }}/
            restart.*
            *.log
            *.err
            *.out

  coverage-test:
    strategy:
      fail-fast: false
      matrix:
        compiler: [ gcc ]
        mpi:      [ openmpi ]
        gpu:      [ nogpu ]
        io:       [ smiol ]
        arch:     [ x86_64 ]
        num_procs: [ 1 ]

        include:
          - mpi: openmpi
            extra_mpi_args: 'export MPI_FLAGS="--allow-run-as-root --oversubscribe"'
          - io: smiol
            extra_io_args: 'unset PIO'

    needs: build-mpas
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -elo pipefail {0}

    container:
      image: ncarcisl/cisldev-${{ matrix.arch }}-${{ inputs.os }}-${{ matrix.compiler }}-${{ matrix.mpi }}${{ matrix.gpu == 'cuda' && '-cuda' || '' }}:devel
    
    steps:
      - uses: actions/checkout@v4

      - name: Install coverage tools
        run: |
          # Install lcov for coverage report generation
          if command -v yum &> /dev/null; then
            # Try to install lcov from EPEL or build from source
            yum install -y epel-release || true
            yum install -y lcov || {
              echo "lcov not available in repositories, installing from source..."
              yum install -y gcc-c++ make
              cd /tmp
              curl -L -o lcov-1.16.tar.gz https://github.com/linux-test-project/lcov/releases/download/v1.16/lcov-1.16.tar.gz
              tar xzf lcov-1.16.tar.gz
              cd lcov-1.16
              make install PREFIX=/usr/local
              cd /
            }
          elif command -v apt-get &> /dev/null; then
            apt-get update && apt-get install -y lcov
          else
            echo "Package manager not found, trying to install lcov manually"
          fi

      - name: Build MPAS-A with coverage
        run: |
          chmod +x .github/workflows/build_mpas.sh

          # Use extra_io_args to set whether to use PIO or SMIOL
          if [ -n "${{ matrix.extra_io_args }}" ]; then
            eval "${{ matrix.extra_io_args }}"
          fi

          # Use extra_accel_args to set whether to use OpenACC
          if [ -n "${{ matrix.extra_accel_args }}" ]; then
            eval "${{ matrix.extra_accel_args }}"
          fi

          # Set coverage compilation flags
          export CFLAGS="${CFLAGS} -fprofile-arcs -ftest-coverage"
          export CXXFLAGS="${CXXFLAGS} -fprofile-arcs -ftest-coverage"
          export FCFLAGS="${FCFLAGS} -fprofile-arcs -ftest-coverage"
          export LDFLAGS="${LDFLAGS} -lgcov"
          timeout 25m .github/workflows/build_mpas.sh

      - name: Run MPAS-A with code coverage test
        run: |
          chmod +x .github/workflows/run_mpas_240km.sh

          # Use extra_mpi_args to set MPI implementation
          if [ -n "${{ matrix.extra_mpi_args }}" ]; then
            eval "${{ matrix.extra_mpi_args }}"
          fi
          .github/workflows/run_mpas_240km.sh ${{ matrix.num_procs }}

      - name: Generate coverage report
        if: always()
        run: |
          cd 240km_${{ matrix.num_procs }}
          
          # Collect coverage data from build directory
          lcov --capture --directory ../build --output-file coverage.info
          
          # Generate HTML report
          genhtml coverage.info --output-directory coverage_report
          
          # Generate summary
          lcov --summary coverage.info

      - name: Upload coverage report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage_report_${{ matrix.compiler }}_${{ matrix.mpi }}_${{ matrix.gpu }}_${{ matrix.io }}
          path: |
            240km_${{ matrix.num_procs }}/coverage_report/
            240km_${{ matrix.num_procs }}/coverage.info


